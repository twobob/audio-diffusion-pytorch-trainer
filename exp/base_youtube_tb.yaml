# @package _global_

# Test with length 65536, batch size 4, logger sampling_steps [3]

sampling_rate: 48000
length: 131072
channels: 2
log_every_n_steps: 500

model:
  _target_: main.module_base.Model
  lr: 1e-4
  lr_beta1: 0.95
  lr_beta2: 0.999
  lr_eps: 1e-6
  lr_weight_decay: 1e-3
  ema_beta: 0.9999
  ema_power: 0.7

  model:
    _target_: audio_diffusion_pytorch.AudioDiffusionModel
    in_channels: ${channels}
    channels: 128
    patch_factor: 16
    patch_blocks: 1
    resnet_groups: 8
    kernel_multiplier_downsample: 2
    multipliers: [1, 2, 4, 4, 4, 4, 4]
    factors: [4, 4, 4, 2, 2, 2]
    num_blocks: [2, 2, 2, 2, 2, 2]
    attentions: [0, 0, 0, 1, 1, 1, 1]
    attention_heads: 8
    attention_features: 64
    attention_multiplier: 2
    use_nearest_upsample: False
    use_skip_scale: True
    use_magnitude_channels: True
    diffusion_sigma_distribution:
      _target_: audio_diffusion_pytorch.UniformDistribution

datamodule:
  _target_: main.module_base.Datamodule
  dataset:
    _target_: audio_data_pytorch.YoutubeDataset
    urls:
      - https://www.youtube.com/watch?v=4-fZ1jrlgJ8
      - https://www.youtube.com/watch?v=ryw6LerPdwk
      - https://www.youtube.com/watch?v=EtQhful8nEY
      - https://www.youtube.com/watch?v=HHW-kIlSdRY
      - https://www.youtube.com/watch?v=nfDfeVCp2_U
      - https://www.youtube.com/watch?v=4ObEnlmwbjc
      - https://www.youtube.com/watch?v=N0pdOF_fMXQ
      - https://www.youtube.com/watch?v=qA97cjrmHxg
      - https://www.youtube.com/watch?v=byegBQxXfpw
      - https://www.youtube.com/watch?v=ImWUuePdMvU
      - https://www.youtube.com/watch?v=et-08e3Blr8
      - https://www.youtube.com/watch?v=8ZnF1leQjIk
      - https://www.youtube.com/watch?v=4JzruC9fqGE
      - https://www.youtube.com/watch?v=w2KVPHlYpmI
      - https://www.youtube.com/watch?v=OwYZQFPhW8E
      - https://www.youtube.com/watch?v=4wGPixEXlzY
      - https://www.youtube.com/watch?v=R9qPDq98B8Q
      - https://www.youtube.com/watch?v=80kTyPVK1os
      - https://www.youtube.com/watch?v=GmefLTWjdD8
      - https://www.youtube.com/watch?v=BNwXkQmkeeY
      - https://www.youtube.com/watch?v=iRZ-Gb50GmI
      - https://www.youtube.com/watch?v=uM2-vV7fkBw
      - https://www.youtube.com/watch?v=T8xN-9PoBPI
      - https://www.youtube.com/watch?v=NnVb2UDorhA
      - https://www.youtube.com/watch?v=lfhMkDoV18k
      - https://www.youtube.com/watch?v=t5YpWuFOi0E
      - https://www.youtube.com/watch?v=e0lLaeDNjcs
      - https://www.youtube.com/watch?v=6d6-OZt_gLA
      - https://www.youtube.com/watch?v=He9-NC6TaeQ
      - https://www.youtube.com/watch?v=hM5xSskZMjI
      - https://www.youtube.com/watch?v=ceCKEkI63Yg
      - https://www.youtube.com/watch?v=8OBxtW35lho
      - https://www.youtube.com/watch?v=mIu08jkUqOA
      - https://www.youtube.com/watch?v=gXT8UI1TmsY
      - https://www.youtube.com/watch?v=je8TULPFgb0
      - https://www.youtube.com/watch?v=u8TM7OLKmW0
      - https://www.youtube.com/watch?v=UbGniohbq98
      - https://www.youtube.com/watch?v=EuW6zBEUGC4
      - https://www.youtube.com/watch?v=N8epegFfcuM
      - https://www.youtube.com/watch?v=cChV_9ckCE0
      - https://www.youtube.com/watch?v=_46N34CtnD4

    root: ${data_dir}
    crop_length: 12 # seconds crops
    transforms:
      _target_: audio_data_pytorch.AllTransform
      source_rate: ${sampling_rate}
      target_rate: ${sampling_rate}
      random_crop_size: ${length}
      loudness: -25
  val_split: 0.01
  batch_size: 58
  num_workers: 2
  pin_memory: True
  persistent_workers: True

callbacks:
  rich_progress_bar:
    _target_: pytorch_lightning.callbacks.RichProgressBar

  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "valid_loss"   # name of the logged metric which determines when model is improving
    save_top_k: 1           # save k best models (determined by above metric)
    save_last: True         # additionaly always save model from last epoch
    mode: "min"             # can be "max" or "min"
    verbose: False
    dirpath: ${logs_dir}/ckpts/${now:%Y-%m-%d-%H-%M-%S}
    filename: '{epoch:02d}-{valid_loss:.3f}'

  model_summary:
    _target_: pytorch_lightning.callbacks.RichModelSummary
    max_depth: 2

 # audio_samples_logger:
 #   _target_: main.module_base.SampleLogger
 #   num_items: 4
 #   channels: ${channels}
 #   sampling_rate: ${sampling_rate}
 #   length: ${length}
 #   sampling_steps: [3]
 #   use_ema_model: True
 #   diffusion_sampler:
 #     _target_: audio_diffusion_pytorch.VSampler
 #   diffusion_schedule:
 #     _target_: audio_diffusion_pytorch.LinearSchedule

#loggers:
#  wandb:
#    _target_: pytorch_lightning.loggers.wandb.WandbLogger
#    project: ${oc.env:WANDB_PROJECT}
#    entity: ${oc.env:WANDB_ENTITY}
#    offline: True  # set True to store all logs only locally
#    job_type: "train"
#    group: ""
#    save_dir: ${logs_dir}

trainer:
  _target_: pytorch_lightning.Trainer
  gpus: 2 # Set `1` to train on GPU, `0` to train on CPU only, and `-1` to train on all GPUs, default `0`
  precision: 32 # Precision used for tensors, default `32`
  accelerator: cuda # `ddp` GPUs train individually and sync gradients, default `None`
  min_epochs: 0
  max_epochs: -1
  enable_model_summary: False
  log_every_n_steps: 1 # Logs metrics every N batches
  check_val_every_n_epoch: null
  val_check_interval: ${log_every_n_steps}  
